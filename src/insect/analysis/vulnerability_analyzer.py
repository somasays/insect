"""
Vulnerability analyzer for dependency and CVE scanning.

This module provides comprehensive vulnerability scanning capabilities including:
- Package dependency vulnerability scanning using multiple databases
- CVE (Common Vulnerabilities and Exposures) database integration
- OSV (Open Source Vulnerabilities) database integration
- License compliance checking
- SBOM (Software Bill of Materials) generation
"""

import contextlib
import json
import logging
import re
import urllib.request
from dataclasses import dataclass
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple
from urllib.error import URLError

from ..finding import Finding, FindingType, Location, Severity
from . import BaseAnalyzer, register_analyzer

logger = logging.getLogger(__name__)


@dataclass
class PackageInfo:
    """Information about a detected package dependency."""

    name: str
    version: str
    ecosystem: str  # npm, pypi, go, rust, maven, etc.
    file_path: str
    line_number: int = 0
    license: Optional[str] = None
    description: Optional[str] = None


@dataclass
class Vulnerability:
    """Information about a vulnerability affecting a package."""

    id: str  # CVE-XXXX-XXXX or GHSA-XXXX-XXXX-XXXX
    summary: str
    severity: str
    cvss_score: Optional[float]
    affected_versions: List[str]
    fixed_version: Optional[str]
    references: List[str]
    published: Optional[datetime]
    modified: Optional[datetime]


class VulnerabilityDatabase:
    """Base class for vulnerability databases."""

    def __init__(self, cache_dir: Path) -> None:
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    def query_vulnerabilities(self, package: PackageInfo) -> List[Vulnerability]:
        """Query vulnerabilities for a given package."""
        raise NotImplementedError

    def is_vulnerable(self, package: PackageInfo, vulnerability: Vulnerability) -> bool:
        """Check if a package version is affected by a vulnerability."""
        return self._version_in_ranges(package.version, vulnerability.affected_versions)

    def _version_in_ranges(self, version: str, ranges: List[str]) -> bool:
        """Check if version falls within vulnerability ranges."""
        # Simple version comparison - can be enhanced with proper semver logic
        for range_spec in ranges:
            if self._version_matches_range(version, range_spec):
                return True
        return False

    def _version_matches_range(self, version: str, range_spec: str) -> bool:
        """Check if version matches a range specification."""
        # Handle common patterns like "< 1.2.3", ">= 2.0.0", "1.2.x"
        if range_spec.startswith("< "):
            return self._compare_versions(version, range_spec[2:]) < 0
        if range_spec.startswith("<= "):
            return self._compare_versions(version, range_spec[3:]) <= 0
        if range_spec.startswith("> "):
            return self._compare_versions(version, range_spec[2:]) > 0
        if range_spec.startswith(">= "):
            return self._compare_versions(version, range_spec[3:]) >= 0
        if range_spec.startswith("== ") or range_spec.startswith("= "):
            return self._compare_versions(version, range_spec[2:]) == 0
        if "*" in range_spec or "x" in range_spec:
            # Wildcard matching
            pattern = range_spec.replace("*", ".*").replace("x", "\\d+")
            return bool(re.match(f"^{pattern}$", version))
        # Exact match
        return version == range_spec

    def _compare_versions(self, v1: str, v2: str) -> int:
        """Compare two version strings. Returns -1, 0, or 1."""
        try:
            parts1 = [int(x) for x in v1.split(".")]
            parts2 = [int(x) for x in v2.split(".")]

            # Pad with zeros
            max_len = max(len(parts1), len(parts2))
            parts1.extend([0] * (max_len - len(parts1)))
            parts2.extend([0] * (max_len - len(parts2)))

            for p1, p2 in zip(parts1, parts2):
                if p1 < p2:
                    return -1
                if p1 > p2:
                    return 1
            return 0
        except (ValueError, AttributeError):
            # Fallback to string comparison
            if v1 < v2:
                return -1
            if v1 > v2:
                return 1
            return 0


class OSVDatabase(VulnerabilityDatabase):
    """OSV (Open Source Vulnerabilities) database integration."""

    BASE_URL = "https://osv-vulnerabilities.storage.googleapis.com"

    def __init__(self, cache_dir: Path) -> None:
        super().__init__(cache_dir)
        self.cache_file = self.cache_dir / "osv_cache.json"
        self.cache_expiry = timedelta(hours=24)

    def query_vulnerabilities(self, package: PackageInfo) -> List[Vulnerability]:
        """Query OSV database for vulnerabilities."""
        try:
            # Try to get from cache first
            cached_data = self._get_cached_data(package)
            if cached_data:
                return self._parse_osv_response(cached_data)

            # Query OSV API
            query_data = {
                "package": {
                    "name": package.name,
                    "ecosystem": self._map_ecosystem(package.ecosystem)
                },
                "version": package.version
            }

            vulnerabilities = self._query_osv_api(query_data)

            # Cache the results
            self._cache_data(package, vulnerabilities)

            return self._parse_osv_response(vulnerabilities)

        except Exception as e:
            logger.warning(f"Failed to query OSV database for {package.name}: {e}")
            return []

    def _map_ecosystem(self, ecosystem: str) -> str:
        """Map internal ecosystem names to OSV ecosystem names."""
        mapping = {
            "pypi": "PyPI",
            "npm": "npm",
            "go": "Go",
            "rust": "crates.io",
            "maven": "Maven",
            "nuget": "NuGet",
            "packagist": "Packagist",
            "rubygems": "RubyGems"
        }
        return mapping.get(ecosystem.lower(), ecosystem)

    def _query_osv_api(self, query_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Query the OSV API."""
        try:
            # Use the batch query endpoint
            url = f"{self.BASE_URL}/v1/querybatch"

            request_data = json.dumps({"queries": [query_data]}).encode('utf-8')

            req = urllib.request.Request(
                url,
                data=request_data,
                headers={'Content-Type': 'application/json'}
            )

            with urllib.request.urlopen(req, timeout=30) as response:
                result = json.loads(response.read().decode('utf-8'))
                return result.get("results", [{}])[0].get("vulns", [])

        except URLError as e:
            logger.warning(f"Failed to query OSV API: {e}")
            return []
        except Exception as e:
            logger.error(f"Error querying OSV API: {e}")
            return []

    def _parse_osv_response(self, vulns: List[Dict[str, Any]]) -> List[Vulnerability]:
        """Parse OSV API response into Vulnerability objects."""
        vulnerabilities = []

        for vuln_data in vulns:
            try:
                # Extract basic information
                vuln_id = vuln_data.get("id", "")
                summary = vuln_data.get("summary", "")

                # Extract severity information
                severity = "UNKNOWN"
                cvss_score = None

                if "severity" in vuln_data:
                    severity_info = vuln_data["severity"]
                    if isinstance(severity_info, list) and severity_info:
                        first_severity = severity_info[0]
                        severity = first_severity.get("type", "UNKNOWN")
                        if "score" in first_severity:
                            cvss_score = float(first_severity["score"])

                # Extract affected versions
                affected_versions = []
                fixed_version = None

                if "affected" in vuln_data:
                    for affected in vuln_data["affected"]:
                        if "ranges" in affected:
                            for range_info in affected["ranges"]:
                                if "events" in range_info:
                                    for event in range_info["events"]:
                                        if "introduced" in event:
                                            affected_versions.append(f">= {event['introduced']}")
                                        elif "fixed" in event and not fixed_version:
                                            fixed_version = event["fixed"]
                                            affected_versions.append(f"< {event['fixed']}")

                # Extract references
                references = []
                if "references" in vuln_data:
                    references = [ref.get("url", "") for ref in vuln_data["references"]]

                # Extract dates
                published = None
                modified = None

                if "published" in vuln_data:
                    with contextlib.suppress(ValueError):
                        published = datetime.fromisoformat(vuln_data["published"].replace("Z", "+00:00"))

                if "modified" in vuln_data:
                    with contextlib.suppress(ValueError):
                        modified = datetime.fromisoformat(vuln_data["modified"].replace("Z", "+00:00"))

                vulnerability = Vulnerability(
                    id=vuln_id,
                    summary=summary,
                    severity=severity,
                    cvss_score=cvss_score,
                    affected_versions=affected_versions,
                    fixed_version=fixed_version,
                    references=references,
                    published=published,
                    modified=modified
                )

                vulnerabilities.append(vulnerability)

            except Exception as e:
                logger.warning(f"Failed to parse vulnerability data: {e}")
                continue

        return vulnerabilities

    def _get_cached_data(self, package: PackageInfo) -> Optional[List[Dict[str, Any]]]:
        """Get cached vulnerability data if available and not expired."""
        try:
            if not self.cache_file.exists():
                return None

            with open(self.cache_file) as f:
                cache = json.load(f)

            cache_key = f"{package.ecosystem}:{package.name}:{package.version}"

            if cache_key in cache:
                cached_entry = cache[cache_key]
                cache_time = datetime.fromisoformat(cached_entry["timestamp"])

                if datetime.now() - cache_time < self.cache_expiry:
                    return cached_entry["data"]

            return None

        except Exception as e:
            logger.debug(f"Failed to read cache: {e}")
            return None

    def _cache_data(self, package: PackageInfo, data: List[Dict[str, Any]]) -> None:
        """Cache vulnerability data."""
        try:
            cache = {}
            if self.cache_file.exists():
                with open(self.cache_file) as f:
                    cache = json.load(f)

            cache_key = f"{package.ecosystem}:{package.name}:{package.version}"
            cache[cache_key] = {
                "timestamp": datetime.now().isoformat(),
                "data": data
            }

            # Clean old cache entries
            now = datetime.now()
            cache = {
                k: v for k, v in cache.items()
                if now - datetime.fromisoformat(v["timestamp"]) < self.cache_expiry
            }

            with open(self.cache_file, 'w') as f:
                json.dump(cache, f, indent=2)

        except Exception as e:
            logger.debug(f"Failed to cache data: {e}")


@register_analyzer
class VulnerabilityAnalyzer(BaseAnalyzer):
    """Analyzer for detecting and reporting vulnerabilities in dependencies."""

    name = "vulnerability"
    description = "Scan dependencies for known vulnerabilities using CVE and OSV databases"
    supported_extensions = {
        ".py", ".txt", ".json", ".yml", ".yaml", ".toml", ".cfg", ".ini",
        ".js", ".ts", ".jsx", ".tsx", ".lock",
        ".go", ".mod", ".sum",
        ".rs", ".java", ".gradle", ".xml", ".pom",
        ".cs", ".csproj", ".fsproj", ".vbproj",
        ".rb", ".gemspec", ".gemfile",
        ".php", ".composer"
    }

    def __init__(self, config: Dict[str, Any]) -> None:
        super().__init__(config)
        analyzer_config = config.get(self.name, {})
        cache_dir = analyzer_config.get("cache_dir")
        self.cache_dir = Path(cache_dir) if cache_dir else Path.home() / ".insect" / "cache"
        self.osv_db = OSVDatabase(self.cache_dir / "osv")

        # Package file patterns for different ecosystems
        self.package_patterns = {
            "pypi": {
                "files": ["requirements.txt", "pyproject.toml", "setup.py", "Pipfile", "poetry.lock"],
                "patterns": [
                    (r"^([a-zA-Z0-9_-]+)\s*[><=!~]+\s*([0-9][0-9a-zA-Z._-]*)", "requirements"),
                    (r'name\s*=\s*["\']([^"\']+)["\']', "setup_py_name"),
                    (r'version\s*=\s*["\']([^"\']+)["\']', "setup_py_version"),
                ]
            },
            "npm": {
                "files": ["package.json", "package-lock.json", "yarn.lock"],
                "patterns": [
                    (r'"([^"]+)"\s*:\s*"([^"]+)"', "package_json"),
                ]
            },
            "go": {
                "files": ["go.mod", "go.sum"],
                "patterns": [
                    (r"^([a-zA-Z0-9./\-_]+)\s+v([0-9][0-9a-zA-Z._+-]*)", "go_mod"),
                ]
            },
            "rust": {
                "files": ["Cargo.toml", "Cargo.lock"],
                "patterns": [
                    (r'\[dependencies\].*?^([a-zA-Z0-9_-]+)\s*=\s*["\']([^"\']+)["\']', "cargo_toml"),
                ]
            }
        }

    def analyze_file(self, file_path: Path) -> List[Finding]:
        """Analyze a file for vulnerable dependencies."""
        findings: List[Finding] = []

        try:
            # Detect package dependencies
            packages = self._detect_packages(file_path)

            if not packages:
                return findings

            logger.info(f"Found {len(packages)} packages in {file_path}")

            # Check each package for vulnerabilities
            for package in packages:
                vulns = self._check_package_vulnerabilities(package)

                for vuln in vulns:
                    severity = self._map_severity(vuln.severity, vuln.cvss_score)

                    # Create finding
                    finding = Finding(
                        id=f"vulnerability-{vuln.id}",
                        analyzer=self.name,
                        severity=severity,
                        title=f"Vulnerable dependency: {package.name} {package.version}",
                        description=self._format_vulnerability_description(package, vuln),
                        location=Location(path=file_path, line_start=package.line_number, column_start=0),
                        type=FindingType.VULNERABILITY,
                        metadata={
                            "package_name": package.name,
                            "package_version": package.version,
                            "ecosystem": package.ecosystem,
                            "vulnerability_id": vuln.id,
                            "cvss_score": vuln.cvss_score,
                            "fixed_version": vuln.fixed_version,
                            "references": vuln.references,
                            "published": vuln.published.isoformat() if vuln.published else None,
                            "modified": vuln.modified.isoformat() if vuln.modified else None,
                        }
                    )

                    findings.append(finding)

        except Exception as e:
            logger.error(f"Error analyzing file {file_path}: {e}")

        return findings

    def _detect_packages(self, file_path: Path) -> List[PackageInfo]:
        """Detect package dependencies in a file."""
        packages: List[PackageInfo] = []
        file_path.name.lower()

        # Determine ecosystem based on file
        ecosystem = self._detect_ecosystem(file_path)
        if not ecosystem:
            return packages

        try:
            content = file_path.read_text(encoding='utf-8', errors='ignore')

            # Use ecosystem-specific parsing
            if ecosystem == "pypi":
                packages.extend(self._parse_python_dependencies(file_path, content))
            elif ecosystem == "npm":
                packages.extend(self._parse_npm_dependencies(file_path, content))
            elif ecosystem == "go":
                packages.extend(self._parse_go_dependencies(file_path, content))
            elif ecosystem == "rust":
                packages.extend(self._parse_rust_dependencies(file_path, content))

        except Exception as e:
            logger.warning(f"Failed to read file {file_path}: {e}")

        return packages

    def _detect_ecosystem(self, file_path: Path) -> Optional[str]:
        """Detect the package ecosystem based on file name and path."""
        file_name = file_path.name.lower()

        # Python ecosystem
        if file_name in ["requirements.txt", "pyproject.toml", "setup.py", "pipfile", "poetry.lock"]:
            return "pypi"

        # Node.js ecosystem
        if file_name in ["package.json", "package-lock.json", "yarn.lock"]:
            return "npm"

        # Go ecosystem
        if file_name in ["go.mod", "go.sum"]:
            return "go"

        # Rust ecosystem
        if file_name in ["cargo.toml", "cargo.lock"]:
            return "rust"

        # Java ecosystem
        if file_name in ["pom.xml", "build.gradle"]:
            return "maven"

        return None

    def _parse_python_dependencies(self, file_path: Path, content: str) -> List[PackageInfo]:
        """Parse Python dependencies from various file formats."""
        packages = []
        file_name = file_path.name.lower()

        if file_name == "requirements.txt":
            packages.extend(self._parse_requirements_txt(file_path, content))
        elif file_name == "pyproject.toml":
            packages.extend(self._parse_pyproject_toml(file_path, content))
        elif file_name == "setup.py":
            packages.extend(self._parse_setup_py(file_path, content))
        elif file_name in ["pipfile", "pipfile.lock"]:
            packages.extend(self._parse_pipfile(file_path, content))

        return packages

    def _parse_requirements_txt(self, file_path: Path, content: str) -> List[PackageInfo]:
        """Parse requirements.txt format."""
        packages = []

        for line_num, line in enumerate(content.split('\n'), 1):
            line = line.strip()
            if not line or line.startswith('#'):
                continue

            # Parse package specification: package>=1.0.0
            match = re.match(r'^([a-zA-Z0-9_.-]+)\s*([><=!~]+)\s*([0-9][0-9a-zA-Z._-]*)', line)
            if match:
                name, operator, version = match.groups()
                packages.append(PackageInfo(
                    name=name.lower(),
                    version=version,
                    ecosystem="pypi",
                    file_path=str(file_path),
                    line_number=line_num
                ))

        return packages

    def _parse_pyproject_toml(self, file_path: Path, content: str) -> List[PackageInfo]:
        """Parse pyproject.toml format."""
        packages = []

        try:
            import toml
            data = toml.loads(content)

            # Check dependencies
            deps = data.get("project", {}).get("dependencies", [])
            for dep in deps:
                match = re.match(r'^([a-zA-Z0-9_.-]+)\s*([><=!~]+)\s*([0-9][0-9a-zA-Z._-]*)', dep)
                if match:
                    name, operator, version = match.groups()
                    packages.append(PackageInfo(
                        name=name.lower(),
                        version=version,
                        ecosystem="pypi",
                        file_path=str(file_path)
                    ))

        except Exception as e:
            logger.debug(f"Failed to parse pyproject.toml: {e}")

        return packages

    def _parse_setup_py(self, file_path: Path, content: str) -> List[PackageInfo]:
        """Parse setup.py format (basic extraction)."""
        packages = []

        # Extract install_requires dependencies
        install_requires_match = re.search(r'install_requires\s*=\s*\[(.*?)\]', content, re.DOTALL)
        if install_requires_match:
            deps_str = install_requires_match.group(1)
            for match in re.finditer(r'["\']([a-zA-Z0-9_.-]+)\s*([><=!~]+)\s*([0-9][0-9a-zA-Z._-]*)["\']', deps_str):
                name, operator, version = match.groups()
                packages.append(PackageInfo(
                    name=name.lower(),
                    version=version,
                    ecosystem="pypi",
                    file_path=str(file_path)
                ))

        return packages

    def _parse_pipfile(self, file_path: Path, content: str) -> List[PackageInfo]:
        """Parse Pipfile format."""
        packages = []

        try:
            import toml
            data = toml.loads(content)

            # Check packages section
            deps = data.get("packages", {})
            for name, version_spec in deps.items():
                if isinstance(version_spec, str):
                    version = version_spec.strip('"\'*>=~!')
                elif isinstance(version_spec, dict):
                    version = version_spec.get("version", "").strip('"\'*>=~!')
                else:
                    continue

                if version:
                    packages.append(PackageInfo(
                        name=name.lower(),
                        version=version,
                        ecosystem="pypi",
                        file_path=str(file_path)
                    ))

        except Exception as e:
            logger.debug(f"Failed to parse Pipfile: {e}")

        return packages

    def _parse_npm_dependencies(self, file_path: Path, content: str) -> List[PackageInfo]:
        """Parse npm dependencies from package.json."""
        packages = []

        try:
            data = json.loads(content)

            # Check dependencies and devDependencies
            for dep_type in ["dependencies", "devDependencies", "peerDependencies"]:
                deps = data.get(dep_type, {})
                for name, version in deps.items():
                    # Clean version string
                    clean_version = re.sub(r'[^0-9.].*$', '', version.lstrip('^~>=<'))
                    if clean_version:
                        packages.append(PackageInfo(
                            name=name,
                            version=clean_version,
                            ecosystem="npm",
                            file_path=str(file_path)
                        ))

        except Exception as e:
            logger.debug(f"Failed to parse package.json: {e}")

        return packages

    def _parse_go_dependencies(self, file_path: Path, content: str) -> List[PackageInfo]:
        """Parse Go dependencies from go.mod."""
        packages = []

        for line_num, line in enumerate(content.split('\n'), 1):
            line = line.strip()

            # Parse require statement: module version
            match = re.match(r'^([a-zA-Z0-9./\-_]+)\s+v([0-9][0-9a-zA-Z._+-]*)', line)
            if match:
                name, version = match.groups()
                packages.append(PackageInfo(
                    name=name,
                    version=version,
                    ecosystem="go",
                    file_path=str(file_path),
                    line_number=line_num
                ))

        return packages

    def _parse_rust_dependencies(self, file_path: Path, content: str) -> List[PackageInfo]:
        """Parse Rust dependencies from Cargo.toml."""
        packages = []

        try:
            import toml
            data = toml.loads(content)

            # Check dependencies section
            deps = data.get("dependencies", {})
            for name, version_spec in deps.items():
                if isinstance(version_spec, str):
                    version = version_spec
                elif isinstance(version_spec, dict):
                    version = version_spec.get("version", "")
                else:
                    continue

                if version:
                    packages.append(PackageInfo(
                        name=name,
                        version=version,
                        ecosystem="rust",
                        file_path=str(file_path)
                    ))

        except Exception as e:
            logger.debug(f"Failed to parse Cargo.toml: {e}")

        return packages

    def _check_package_vulnerabilities(self, package: PackageInfo) -> List[Vulnerability]:
        """Check a package for known vulnerabilities."""
        try:
            # Query OSV database
            vulnerabilities = self.osv_db.query_vulnerabilities(package)

            # Filter vulnerabilities that actually affect this version
            affecting_vulns = []
            for vuln in vulnerabilities:
                if self.osv_db.is_vulnerable(package, vuln):
                    affecting_vulns.append(vuln)

            return affecting_vulns

        except Exception as e:
            logger.warning(f"Failed to check vulnerabilities for {package.name}: {e}")
            return []

    def _map_severity(self, osv_severity: str, cvss_score: Optional[float]) -> Severity:
        """Map OSV severity to our severity scale."""
        if cvss_score is not None:
            if cvss_score >= 9.0:
                return Severity.CRITICAL
            if cvss_score >= 7.0:
                return Severity.HIGH
            if cvss_score >= 4.0:
                return Severity.MEDIUM
            return Severity.LOW

        # Fallback to text-based severity
        severity_lower = osv_severity.lower()
        if severity_lower in ["critical", "high"]:
            return Severity.HIGH
        if severity_lower in ["medium", "moderate"]:
            return Severity.MEDIUM
        if severity_lower in ["low", "minor"]:
            return Severity.LOW
        return Severity.MEDIUM

    def _format_vulnerability_description(self, package: PackageInfo, vuln: Vulnerability) -> str:
        """Format vulnerability description for the finding."""
        description = f"Package {package.name} version {package.version} has a known vulnerability.\n\n"

        if vuln.summary:
            description += f"Summary: {vuln.summary}\n\n"

        if vuln.cvss_score:
            description += f"CVSS Score: {vuln.cvss_score}\n"

        if vuln.fixed_version:
            description += f"Fixed in version: {vuln.fixed_version}\n"

        if vuln.references:
            description += "\nReferences:\n"
            for ref in vuln.references[:3]:  # Limit to first 3 references
                description += f"- {ref}\n"

        description += f"\nRecommendation: Update {package.name} to version {vuln.fixed_version or 'latest'} or later."

        return description

    def _should_analyze_file(self, file_path: Path) -> bool:
        """Check if a file should be analyzed for vulnerabilities."""
        return self.can_analyze_file(file_path)

    def generate_sbom(self, target_path: Path) -> Dict[str, Any]:
        """Generate Software Bill of Materials for the target."""
        sbom: Dict[str, Any] = {
            "bomFormat": "CycloneDX",
            "specVersion": "1.4",
            "version": 1,
            "metadata": {
                "timestamp": datetime.now().isoformat(),
                "tools": [{"name": "insect", "version": "0.1.0"}],
                "component": {
                    "type": "application",
                    "name": target_path.name,
                    "version": "unknown"
                }
            },
            "components": []
        }

        # Collect all packages from the target
        all_packages: Set[Tuple[str, str, str]] = set()  # (name, version, ecosystem)

        for file_path in target_path.rglob("*"):
            if file_path.is_file() and self._should_analyze_file(file_path):
                packages = self._detect_packages(file_path)
                for pkg in packages:
                    all_packages.add((pkg.name, pkg.version, pkg.ecosystem))

        # Convert to SBOM components
        for name, version, ecosystem in all_packages:
            component = {
                "type": "library",
                "name": name,
                "version": version,
                "purl": f"pkg:{ecosystem}/{name}@{version}",
                "scope": "required"
            }
            sbom["components"].append(component)

        return sbom
